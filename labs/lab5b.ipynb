{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QuUAgQFQlsJU"
   },
   "source": [
    "# [CSCI 3397/PSYC 3317] Lab 5b: Linear Regression\n",
    "\n",
    "**Posted:** Thursday, February 17, 2022\n",
    "\n",
    "**Due:** Thursday, February 24, 2022\n",
    "\n",
    "__Total Points__: 8 pts\n",
    "\n",
    "__Submission__: please rename the .ipynb file as __\\<your_username\\>_lab5b.ipynb__ before you submit it to canvas. Example: weidf_lab5b.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## utility functions\n",
    "\n",
    "# dataset split\n",
    "def data_split(N, ratio=[6,2,2]):\n",
    "    # generate a shuffle array\n",
    "    shuffle_idx = np.arange(N)\n",
    "    np.random.shuffle(shuffle_idx)\n",
    "    # divide into train-val-test by the ratio\n",
    "    data_split = (np.cumsum(ratio)/float(sum(ratio))*N).astype(int)\n",
    "    out_idx = [None] * len(ratio)\n",
    "    out_idx[0] = shuffle_idx[:data_split[0]]\n",
    "    for i in range(1,len(ratio)):\n",
    "        out_idx[i] = shuffle_idx[data_split[i-1] : data_split[i]]\n",
    "    return out_idx\n",
    "\n",
    "def MSE(y,y_hat):\n",
    "    # Lec. 9, page 19\n",
    "    return ((y-y_hat)**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data generation\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "# gt polynomial: y = 0.73x + 0.58\n",
    "theta_gt = [0.58, 0.73]  # theta_0,theta_1\n",
    "num_pt = 50\n",
    "\n",
    "X = np.random.uniform(4, 10, num_pt).reshape(-1,1)\n",
    "Y = theta_gt[0] + theta_gt[1] * X + 0.5 *np.random.normal(0, 1, num_pt).reshape(-1,1)\n",
    "\n",
    "# for visualization\n",
    "XX = np.linspace(4,10,100).reshape(-1,1)\n",
    "\n",
    "train_idx, val_idx, test_idx = data_split(len(Y))\n",
    "\n",
    "X_train, Y_train = X[train_idx], Y[train_idx]\n",
    "X_val, Y_val = X[val_idx], Y[val_idx]\n",
    "X_test, Y_test = X[test_idx], Y[test_idx]\n",
    "\n",
    "plt.plot(X_train,Y_train,'ro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Use 1-dim linear regression formula\n",
    "\n",
    "Lec. 9, page 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_1 = (X_train*Y_train).mean()-X_train.mean()*Y_train.mean()\n",
    "theta_1 = theta_1/ ((X_train**2).mean()-X_train.mean()**2)\n",
    "theta_0 = Y_train.mean()-theta_1*X_train.mean()\n",
    "\n",
    "plt.plot(X_train,Y_train,'ro')\n",
    "plt.plot(XX,XX*theta_1+theta_0,'b-')\n",
    "plt.legend(['data', 'regression result'])\n",
    "\n",
    "print('gt theta', theta_gt)\n",
    "print('estimated theta (1-dim formula)', [theta_0,theta_1])\n",
    "\n",
    "\n",
    "# evaluation on the training data\n",
    "Y_train_hat = X_train*theta_1+theta_0\n",
    "print('MSE error', MSE(Y_train, Y_train_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Use N-dim linear regression formula\n",
    "\n",
    "lec.9, page 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_aug = np.hstack([np.ones([len(X_train),1]),X_train])\n",
    "\n",
    "theta_nd = np.linalg.solve(np.matmul(X_train_aug.T, X_train_aug), np.matmul(X_train_aug.T, Y_train))\n",
    "print('estimated theta (N-dim formula)', theta_nd)\n",
    "\n",
    "# evaluation on the training data\n",
    "Y_train_hat = X_train*theta_nd[1]+theta_nd[0]\n",
    "print('MSE error', MSE(Y_train, Y_train_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Polynomial regression (Linear regression + polynomial feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eLZxOOH-lsU3"
   },
   "source": [
    "## 2.1 Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "# gt polynomial: y = x^2 -10x +25\n",
    "num_pt = 10\n",
    "\n",
    "X2 = np.random.uniform(4, 10, num_pt).reshape(-1,1)\n",
    "theta_gt2 = [25,-10,1]\n",
    "Y2 = theta_gt2[0] + theta_gt2[1]*X2 +theta_gt2[2]*X2**2 + 0.5 *np.random.normal(0, 1, num_pt).reshape(-1,1)\n",
    "\n",
    "# for visualization\n",
    "XX2 = np.linspace(4,10,100).reshape(-1,1)\n",
    "\n",
    "train_idx2, val_idx2, test_idx2 = data_split(len(Y2))\n",
    "\n",
    "X_train2, Y_train2 = X2[train_idx2], Y2[train_idx2]\n",
    "X_val2, Y_val2 = X2[val_idx2], Y2[val_idx2]\n",
    "X_test2, Y_test2 = X2[test_idx2], Y2[test_idx2]\n",
    "\n",
    "plt.plot(X_train2,Y_train2,'ro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Use N-dim linear regression formula\n",
    "\n",
    "lec.9, page 25,30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2_aug = np.hstack([np.ones([len(X_train2),1]),X_train2,X_train2**2])\n",
    "\n",
    "theta_nd2 = np.linalg.solve(np.matmul(X_train2_aug.T, X_train2_aug), np.matmul(X_train2_aug.T, Y_train2))\n",
    "print('gt theta', theta_gt2)\n",
    "print('estimated theta (N-dim formula)',theta_nd2)\n",
    "\n",
    "# evaluation on the training data\n",
    "Y_train2_hat = X_train2 * X_train2 * theta_nd2[2] + X_train2 * theta_nd2[1]+theta_nd2[0]\n",
    "print('MSE error', MSE(Y_train2, Y_train2_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise (8 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) [3 pts] Polynomial regressor for any order of K\n",
    "\n",
    "- [2 pt] Build a function to do polynomial regression with the input order K (e.g., $\\sum_{i=0}^{k}\\theta_ix^i$) and return the estimated theta\n",
    "- [1 pt] Sanity check: for K=2, print the MSE error for the train data (X_train2, Y_train2) in section 2 and check if the MSE values agree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hint: create the feature in the beginning and use for-loop to fill in each feature dimension\n",
    "def train_PR(x,y,k):\n",
    "    ### Your code starts here\n",
    "    \n",
    "    ### Your code ends here\n",
    "    # retun estimated theta\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) [5 pts] Model selection\n",
    "Let `Ks=np.arange(1,11)`\n",
    "- (a) [1 pt] For each K value, train a polynomial regression model with order=K, evaluate its MSE on the training data.\n",
    "- (b) [1 pt] Draw a line-plot of the training MSE (`plt.plot(x,y,'-')`) and answer \"which K shall we choose if the goal is to minimize the training error\"\n",
    "- (c) [1 pt] Evaluate the trained models (different K values) above on the validation data and answer \"which K shall we choose if the goal is to minimize the validation error\"\n",
    "- (d) [1 pt] Repeat (c) on the test data as the \"final/real-world\" evaluation.\n",
    "- (e) [1 pt] Which model selection criteria is better: minimize training error or validation error? Briefly explain why.\n",
    "\n",
    "Lec. 9, slide 42 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code starts here\n",
    "\n",
    "### Your code ends here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "lab1.ipynb",
   "provenance": [
    {
     "file_id": "1_d49_U8Zrz_Ac-QWgXFBzr4CJ4S8fKe1",
     "timestamp": 1614174979410
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
