{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IAae8nayHhH2"
   },
   "source": [
    "# [CSCI 3397/PSYC 3317] Lab 6b: Optimization and PyTorch Basics\n",
    "\n",
    "**Posted:** Thursday, February 24, 2022\n",
    "\n",
    "**Due:** Thursday, March 3, 2022\n",
    "\n",
    "__Total Points__: 2 pts\n",
    "\n",
    "__Submission__: please rename the .ipynb file as __\\<your_username\\>\\_lab6b.ipynb__ before you submit it to canvas. Example: weidf_lab6b.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Optimization Basics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's implement the gradient descend method to find the minimum value for the function $g(x) = 0.066x^4-0.32x^3-0.85x^2+ 4.2x+8.2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## function definition\n",
    "def g(x):\n",
    "  # return the value of the defined g(x) at value x\n",
    "  return 8.2 + 4.2*x**1 -0.85*x**2 -0.32*x**3+ 0.066*x**4\n",
    "\n",
    "def Dg(x):\n",
    "  # return the value of the gradient of the defined g(x) at value x\n",
    "  return 4.2 -1.7*x -0.96*x**2+ 0.264*x**3\n",
    "\n",
    "## gradient descent\n",
    "def optimizer_grad_descent(x0, grad, alpha = 0.1, num_step = 100, x_ran=None):\n",
    "  for x in range(num_step):\n",
    "    # gradient descent update    \n",
    "    x0 = x0 - alpha * grad(x0)\n",
    "    if x_ran is not None:\n",
    "      # clip the value\n",
    "      x0 = np.clip(x0, x_ran[0], x_ran[1])\n",
    "  return x0\n",
    "\n",
    "# find the minimum value within x_ran, starting from x0\n",
    "x_ran = [-4, 6]\n",
    "x0 = 5.5\n",
    "x1 = optimizer_grad_descent(x0, Dg, alpha = 0.1, x_ran = x_ran)\n",
    "\n",
    "# plot result\n",
    "print('initial result: x=%.2f, g(x)=%.2f' %(x0, g(x0)))\n",
    "print('final result: x=%.2f, g(x)=%.2f' %(x1, g(x1)))\n",
    "xx = np.linspace(*x_ran, 100)\n",
    "plt.plot(xx, g(xx))\n",
    "plt.plot(x0,g(x0), 'ro')\n",
    "plt.plot(x1,g(x1), 'kx', markersize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2 pts) Exercise\n",
    "Let's implement a better optimization method: \"gradient descend with momentum\" method described in [distill.pub paper](https://distill.pub/2017/momentum/). \n",
    "The high-level idea is that instead of trusting the current gradient 100%, we can linearly combine the previous gradients (i.e., carry on the momemtum) and the current gradient. With this, it can stabilize the search moves (e.g., not affected by noisy local gradient) and get out of stuck of the local optima where the current graident is 0.\n",
    "\n",
    "Here's the new Update formula: \n",
    "- $z^{k+1}=\\beta z^{k}+ \\dfrac{dg}{dx}(x^{k})$\n",
    "- $x^{k+1}=x^{k+1} -\\alpha z^{k+1}$\n",
    "\n",
    "Note that, if $\\beta=0$, the update rule is the same as the gradient descent method.\n",
    "\n",
    "Let's implement it and find the global mimina for this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## gradient descent with momemtum\n",
    "def optimizer_grad_descent_momentum(x0, grad, alpha = 0.1, beta = 0.99, num_step = 100, x_ran=None):\n",
    "    v0 = 0\n",
    "    for x in range(num_step):\n",
    "        # gradient descend with momentum update    \n",
    "        ### Your code starts here\n",
    "        \n",
    "        ### Your code ends here        \n",
    "        if x_ran is not None:\n",
    "            # clip the value\n",
    "            x0 = np.clip(x0, x_ran[0], x_ran[1])\n",
    "    return x0\n",
    "\n",
    "# find the minimum value within x_ran, starting from x0\n",
    "x_ran = [-4, 6]\n",
    "x0 = 5.5\n",
    "x2 = optimizer_grad_descent_momentum(x0, Dg, x_ran = x_ran)\n",
    "\n",
    "# plot result\n",
    "print('initial result: x=%.2f, g(x)=%.2f' %(x0, g(x0)))\n",
    "print('final result: x=%.2f, g(x)=%.2f' %(x1, g(x1)))\n",
    "xx = np.linspace(*x_ran, 100)\n",
    "plt.plot(xx, g(xx))\n",
    "plt.plot(x0,g(x0), 'ro')\n",
    "plt.plot(x2,g(x2), 'kx', markersize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKSHYh1gby1h"
   },
   "source": [
    "# 2. PyTorch Basics\n",
    "\n",
    "We will explain how to implement machine learning building blocks (model, loss, and optimization) in PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2drtxcMec0YU"
   },
   "source": [
    "### What is PyTorch?\n",
    "1. A Python GPU-accelerated tensor library (NumPy, but faster)\n",
    "2. Differentiable Programming with dynamic computation graphs\n",
    "3. Flexible and efficient **neural network** library\n",
    "4. Python-first framework (easy to integrate with other Python libraries, debug, and extend)\n",
    "  + Quick conversion from & to NumPy array, integration with other Python libs.\n",
    "  + Your favorite Python debugger.\n",
    "  + Adding custom ops with Python/c++ extension. \n",
    "  + Running in purely c++ environment with the c++ API.\n",
    "\n",
    "Useful links:\n",
    "\n",
    "+ PyTorch documentation: https://pytorch.org/docs/stable/index.html\n",
    "  -  Most math operations can be found as `torch.*` or `Tensor.*`.\n",
    "+ [Optional] PyTorch official tutorials: https://pytorch.org/tutorials/\n",
    "  - Transfer learning tutorial: https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "+ [Optional] PyTorch examples: https://github.com/pytorch/examples/\n",
    "  - DCGAN, ImageNet training, Reinforcement Learning, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nCij29tonH84"
   },
   "source": [
    "### PyTorch Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4019,
     "status": "ok",
     "timestamp": 1645092994595,
     "user": {
      "displayName": "Donglai Wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghp_r_BM-hcnzseHQOqKEog51cEpxJX-9EaMyIO=s64",
      "userId": "05000800795689376079"
     },
     "user_tz": 300
    },
    "id": "FgmnwpcHf8U0",
    "outputId": "455e0f5b-8e0b-492e-9273-5253d4630be4"
   },
   "outputs": [],
   "source": [
    "# install torch and torchvision (a utility library for computer vision that provides many public datasets and pre-trained models)\n",
    "# already installed on jupyterhub\n",
    "# !pip install torch torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mj3oX5WEkM8P"
   },
   "source": [
    "## 2.1 GPU-accelerated Tensor Library\n",
    "\n",
    "The syntax of the torch tensor library is similar to that of numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dPdEDFjyf94_"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 160,
     "status": "ok",
     "timestamp": 1645093001721,
     "user": {
      "displayName": "Donglai Wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghp_r_BM-hcnzseHQOqKEog51cEpxJX-9EaMyIO=s64",
      "userId": "05000800795689376079"
     },
     "user_tz": 300
    },
    "id": "3cVfJH3PgvCE",
    "outputId": "25c7ad47-1aca-407e-b3b1-964923b0f7c3"
   },
   "outputs": [],
   "source": [
    "# Create a 3x5 matrix filled with zeros\n",
    "x = torch.zeros(3, 5)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1645093001721,
     "user": {
      "displayName": "Donglai Wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghp_r_BM-hcnzseHQOqKEog51cEpxJX-9EaMyIO=s64",
      "userId": "05000800795689376079"
     },
     "user_tz": 300
    },
    "id": "qauqxYzmgQBO",
    "outputId": "feaf7aec-707d-46d5-97b0-017ef7e0a734"
   },
   "outputs": [],
   "source": [
    "# Create a 3x5 matrix filled with random values from a standard normal distribution\n",
    "y = torch.randn(3, 5)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1645093001722,
     "user": {
      "displayName": "Donglai Wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghp_r_BM-hcnzseHQOqKEog51cEpxJX-9EaMyIO=s64",
      "userId": "05000800795689376079"
     },
     "user_tz": 300
    },
    "id": "pUS9LmmF58gI",
    "outputId": "ac09c47d-41a6-4988-8403-70be9008e6f4"
   },
   "outputs": [],
   "source": [
    "# Shape manipulations\n",
    "print('\\n.t()  (transpose): ')\n",
    "print(y.t())\n",
    "\n",
    "print('.reshape(5, 3): ')\n",
    "print(y.reshape(5, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1645093001857,
     "user": {
      "displayName": "Donglai Wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghp_r_BM-hcnzseHQOqKEog51cEpxJX-9EaMyIO=s64",
      "userId": "05000800795689376079"
     },
     "user_tz": 300
    },
    "id": "m-qEF8if6VkQ",
    "outputId": "2a0cbb03-b150-41db-b4d0-3e7f4c3cdf9c"
   },
   "outputs": [],
   "source": [
    "# Slicing\n",
    "print(y[1:])\n",
    "\n",
    "# Slicing + select every two elements\n",
    "print(y[1:, ::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1645093001858,
     "user": {
      "displayName": "Donglai Wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghp_r_BM-hcnzseHQOqKEog51cEpxJX-9EaMyIO=s64",
      "userId": "05000800795689376079"
     },
     "user_tz": 300
    },
    "id": "PGpFKCBEgbJe",
    "outputId": "52e712c4-693e-43d0-abfb-66b754eea7c3"
   },
   "outputs": [],
   "source": [
    "# Basic arithmetics\n",
    "print(x + 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1645093001858,
     "user": {
      "displayName": "Donglai Wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghp_r_BM-hcnzseHQOqKEog51cEpxJX-9EaMyIO=s64",
      "userId": "05000800795689376079"
     },
     "user_tz": 300
    },
    "id": "gvoZaG8NkbHx",
    "outputId": "56c10945-1149-4c5b-b5fe-ca2939f391b7"
   },
   "outputs": [],
   "source": [
    "print(y * (x + 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 173,
     "status": "ok",
     "timestamp": 1645093002028,
     "user": {
      "displayName": "Donglai Wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghp_r_BM-hcnzseHQOqKEog51cEpxJX-9EaMyIO=s64",
      "userId": "05000800795689376079"
     },
     "user_tz": 300
    },
    "id": "Zktd6b7wkgF2",
    "outputId": "f3df13e0-92bc-4fbd-826e-931dc21c2b1b"
   },
   "outputs": [],
   "source": [
    "print((y * (x + 2)).exp())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n2dhiDLzkyQF"
   },
   "source": [
    "#### GPU Acceleration (BC jupyterhub doesn't have GPU support)\n",
    "\n",
    "Everything can be run on a GPU\n",
    "\n",
    "First, let us create a [`torch.device`](https://pytorch.org/docs/stable/tensor_attributes.html#torch-device) object representing a GPU device."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "MPdqlb1CkmqQ"
   },
   "source": [
    "cuda0 = torch.device('cuda:0')  # pick the GPU at index 0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13022,
     "status": "ok",
     "timestamp": 1645093015206,
     "user": {
      "displayName": "Donglai Wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghp_r_BM-hcnzseHQOqKEog51cEpxJX-9EaMyIO=s64",
      "userId": "05000800795689376079"
     },
     "user_tz": 300
    },
    "id": "LCYhVhc-lE7N",
    "outputId": "07595881-7bd5-4667-e95c-2117838f02d7"
   },
   "source": [
    "# Move a tensor from CPU to GPU\n",
    "# NOTE: the first time you access a GPU, a context is created so this may take a\n",
    "# few seconds. But subsequent uses will be fast.\n",
    "\n",
    "cuda_y = y.to(cuda0)\n",
    "print(cuda_y)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1645093015206,
     "user": {
      "displayName": "Donglai Wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghp_r_BM-hcnzseHQOqKEog51cEpxJX-9EaMyIO=s64",
      "userId": "05000800795689376079"
     },
     "user_tz": 300
    },
    "id": "QhhaWnPvlQ0F",
    "outputId": "1076191d-2920-4a2d-c631-851d5468b78b"
   },
   "source": [
    "# Or directly creating a tensor on GPU\n",
    "cuda_x = torch.zeros(3, 5, device=cuda0)\n",
    "print(cuda_x)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 184,
     "status": "ok",
     "timestamp": 1645093015384,
     "user": {
      "displayName": "Donglai Wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghp_r_BM-hcnzseHQOqKEog51cEpxJX-9EaMyIO=s64",
      "userId": "05000800795689376079"
     },
     "user_tz": 300
    },
    "id": "QnaL5mNimjXo",
    "outputId": "cc327f31-7d0e-4d81-bc10-ca75494947fd"
   },
   "source": [
    "# All functions and methods work on GPU tensors\n",
    "print((cuda_y * (cuda_x + 2)).exp())  # values match the CPU results above!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJb9shauw6Bu"
   },
   "source": [
    "### NumPy Bridge\n",
    "\n",
    "Converting a `torch.Tensor` to a `np.ndarray` and vice versa is a breeze.\n",
    "\n",
    "The `torch.Tensor` and `np.ndarray` will share their underlying memory locations (if the `torch.Tensor` is on CPU and `dtype` is the same), and changing one will change the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wjPmAYWIxeM3"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1645093015385,
     "user": {
      "displayName": "Donglai Wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghp_r_BM-hcnzseHQOqKEog51cEpxJX-9EaMyIO=s64",
      "userId": "05000800795689376079"
     },
     "user_tz": 300
    },
    "id": "VHPeZwjPWwlx",
    "outputId": "371eb5dd-f0e7-4061-c33c-a9fea74e42fb"
   },
   "outputs": [],
   "source": [
    "# convert a torch tensor into a numpy array\n",
    "x = torch.randn(5)\n",
    "x_np1 = x.numpy()\n",
    "x_np2 = np.asarray(x)\n",
    "\n",
    "print(x)\n",
    "print(x_np1)\n",
    "print(x_np2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1645093015385,
     "user": {
      "displayName": "Donglai Wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghp_r_BM-hcnzseHQOqKEog51cEpxJX-9EaMyIO=s64",
      "userId": "05000800795689376079"
     },
     "user_tz": 300
    },
    "id": "WfVwkxI8x5ks",
    "outputId": "fbeeb094-8ded-470c-cfba-411b96c931ec"
   },
   "outputs": [],
   "source": [
    "# convert a numpy array into a torch tensor\n",
    "\n",
    "a = np.random.randn(3, 4)\n",
    "a_pt = torch.as_tensor(a)\n",
    "print(a)\n",
    "print(a_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1645093015386,
     "user": {
      "displayName": "Donglai Wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghp_r_BM-hcnzseHQOqKEog51cEpxJX-9EaMyIO=s64",
      "userId": "05000800795689376079"
     },
     "user_tz": 300
    },
    "id": "6RmnP6Sayb19",
    "outputId": "61535660-d699-4238-f2d1-702809efc4b2"
   },
   "outputs": [],
   "source": [
    "# the resulting CPU Tensor shares memory with the array!\n",
    "# change the tensor array -> change the orignial numpy array\n",
    "# if you want a different copy: a_pt = torch.as_tensor(a.copy())\n",
    "\n",
    "a_pt[0] = -1\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EAvixGtnv459"
   },
   "source": [
    "## 2.2 Flexible and Efficient Neural Network Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ni-h3bBGz0kf"
   },
   "source": [
    "The [`torch.nn`](https://pytorch.org/docs/stable/nn.html) and [`torch.optim`](https://pytorch.org/docs/stable/optim.html) packages provide many efficient implementations of neural network components:\n",
    "  + Affine layers and [activation functions](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity)\n",
    "  + Normalization methods\n",
    "  + [Initialization schemes](https://pytorch.org/docs/stable/nn.html#torch-nn-init)\n",
    "  + [Loss functions](https://pytorch.org/docs/stable/nn.html#loss-functions)\n",
    "  + [Embeddings](https://pytorch.org/docs/stable/nn.html#sparse-layers)\n",
    "  + [Distributed and Multi-GPU training](https://pytorch.org/docs/stable/nn.html#dataparallel-layers-multi-gpu-distributed)\n",
    "  + [Gradient-based optimizers](https://pytorch.org/docs/stable/optim.html)\n",
    "  + [Learning rate schedulers](https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate)\n",
    "  + etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "48lBcWUIhc6Y"
   },
   "source": [
    "### (a1) Model: Linear Layer\n",
    "\n",
    "We will use the [fully connected linear layer (`nn.Linear`)](https://pytorch.org/docs/stable/nn.html#torch.nn.Linear). \n",
    "A fc layer performs an affine transform with a 2D weight parameter $\\mathbf{w}$ and a 1D bias parameter $\\mathbf{b}$:\n",
    "\n",
    "$$ f(\\mathbf{x}) = \\mathbf{w}^\\mathrm{T} \\mathbf{x} + \\mathbf{b}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4XWfNgtI0NE0"
   },
   "outputs": [],
   "source": [
    "# all popular neural network layers\n",
    "import torch.nn as nn \n",
    "# handy for simple functions\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1645093015386,
     "user": {
      "displayName": "Donglai Wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghp_r_BM-hcnzseHQOqKEog51cEpxJX-9EaMyIO=s64",
      "userId": "05000800795689376079"
     },
     "user_tz": 300
    },
    "id": "DpkSxb3UvZYF",
    "outputId": "bb857aeb-ec19-4605-a1f1-8a7b0431aeb3"
   },
   "outputs": [],
   "source": [
    "# input x: 1D array of size 4\n",
    "# output: 1D array of size 8\n",
    "fc = nn.Linear(in_features=4, out_features=8)\n",
    "print(fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 176,
     "status": "ok",
     "timestamp": 1645093015555,
     "user": {
      "displayName": "Donglai Wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghp_r_BM-hcnzseHQOqKEog51cEpxJX-9EaMyIO=s64",
      "userId": "05000800795689376079"
     },
     "user_tz": 300
    },
    "id": "MRYaIS5vzyoF",
    "outputId": "7ae41288-1739-4d77-cf6c-079cbb07fbf1"
   },
   "outputs": [],
   "source": [
    "# It has two parameters, the weight and the bias\n",
    "for name, p in fc.named_parameters():\n",
    "    print('param name: {}\\t shape: {}'.format(name, p.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1645093015556,
     "user": {
      "displayName": "Donglai Wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghp_r_BM-hcnzseHQOqKEog51cEpxJX-9EaMyIO=s64",
      "userId": "05000800795689376079"
     },
     "user_tz": 300
    },
    "id": "mKNxg_ggfaCN",
    "outputId": "d789e27e-b648-4433-a799-6358872efb02"
   },
   "outputs": [],
   "source": [
    "fc.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1645093015556,
     "user": {
      "displayName": "Donglai Wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghp_r_BM-hcnzseHQOqKEog51cEpxJX-9EaMyIO=s64",
      "userId": "05000800795689376079"
     },
     "user_tz": 300
    },
    "id": "KgGxaH8P0k6d",
    "outputId": "3920ebd6-85fb-4e02-fe5a-5c23dc24fd4b"
   },
   "outputs": [],
   "source": [
    "# These parameters by default have `requires_grad=True`, so they will collect gradients!\n",
    "print(fc.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X28ALh9ihqSp"
   },
   "source": [
    "### (a2) Model: Sigmoid Layer\n",
    "\n",
    "$$ \\sigma(x) = \\frac{1}{1+e^{-x}}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1645093015557,
     "user": {
      "displayName": "Donglai Wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghp_r_BM-hcnzseHQOqKEog51cEpxJX-9EaMyIO=s64",
      "userId": "05000800795689376079"
     },
     "user_tz": 300
    },
    "id": "21nZqKk009u2",
    "outputId": "50fe7fc4-b229-4877-d2e6-907113bbd0b2"
   },
   "outputs": [],
   "source": [
    "# Let's construct an input tensor with 2 dimensions:\n",
    "#   - batch dimensionsize: 2\n",
    "#   - input size: 4\n",
    "x = torch.randn(2, 4)\n",
    "\n",
    "result_linear = fc(x)\n",
    "result_logistic = F.sigmoid(result_linear)\n",
    "print(\"linear layer output: range=[-\\infty, \\infty]\")\n",
    "print(result_linear)\n",
    "print(\"logistic output: range=[0, 1]\")\n",
    "print(result_logistic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "krtyRiOdjCKv"
   },
   "source": [
    "### (b) Loss: Cross entropy and MSE Loss Function\n",
    "\n",
    "[Documentation](https://pytorch.org/docs/stable/nn.functional.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 150,
     "status": "ok",
     "timestamp": 1645093015702,
     "user": {
      "displayName": "Donglai Wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghp_r_BM-hcnzseHQOqKEog51cEpxJX-9EaMyIO=s64",
      "userId": "05000800795689376079"
     },
     "user_tz": 300
    },
    "id": "HBh0R7zV7TZK",
    "outputId": "6466a104-dcee-4f45-8bf1-b64dfca52fd1"
   },
   "outputs": [],
   "source": [
    "# generate arbitrary classification label\n",
    "target = result_linear>0.1\n",
    "target = target.to(torch.float) # need to convert it to float\n",
    "\n",
    "# Let's try MSE loss\n",
    "loss_mse = F.mse_loss(result_logistic, target)\n",
    "loss_bce = F.binary_cross_entropy(result_logistic, target)\n",
    "print(loss_mse, loss_bce)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GReMBZkjjv98"
   },
   "source": [
    "### (c) Autograd and Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uFpp4aL2j3tI"
   },
   "source": [
    "#### Gradient Computation\n",
    "PyTorch keeps track of your computations and the gradient is automatically computed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1645093015703,
     "user": {
      "displayName": "Donglai Wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghp_r_BM-hcnzseHQOqKEog51cEpxJX-9EaMyIO=s64",
      "userId": "05000800795689376079"
     },
     "user_tz": 300
    },
    "id": "0HBUX4To7Zie",
    "outputId": "179b04c8-c992-4832-fc60-6067d6b4a565"
   },
   "outputs": [],
   "source": [
    "# Compute gradients\n",
    "loss_mse.backward()\n",
    "print(fc.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZURHGQakF9Q"
   },
   "source": [
    "#### Optimizer\n",
    "\n",
    "We can code up a naive optimizer with manual gradient updates like before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1645093015703,
     "user": {
      "displayName": "Donglai Wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghp_r_BM-hcnzseHQOqKEog51cEpxJX-9EaMyIO=s64",
      "userId": "05000800795689376079"
     },
     "user_tz": 300
    },
    "id": "5RXQNbrf7jy9",
    "outputId": "aeead982-3b79-4252-c495-e975694d314c"
   },
   "outputs": [],
   "source": [
    "# We can manually perform GD via a loop\n",
    "print('bias before GD', fc.bias)\n",
    "lr = 0.5\n",
    "with torch.no_grad():  \n",
    "    # this context manager tells PyTorch that we don't want ops inside to be \n",
    "    # tracked by autograd!\n",
    "    # o/w PyTorch will try to automatically compute the gradient of this gradient operation too.\n",
    "    for p in fc.parameters():\n",
    "        p -= lr * p.grad\n",
    "        \n",
    "print('bias after one-step GD', fc.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OZq4QtJ8F5v4"
   },
   "source": [
    "More easily, we can use the provided [`torch.optim`](https://pytorch.org/docs/stable/optim.html#torch.optim) optimizers (e.g. GD+momentum and many advanced optimizers). We will see how to use the [`torch.optim.SGD`](https://pytorch.org/docs/stable/optim.html#torch.optim.SGD) optimizer in a second!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ou68C8c-lQu4"
   },
   "source": [
    "# 3. Logistic Regression in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v-U1tDZkn3gc"
   },
   "source": [
    "## (a) Data\n",
    "- download and pre-procoss the dataset (x,y)\n",
    "- divide them into train, val, and test sets in a 6:2:2 ratio\n",
    "- convert from numpy to pytorch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 333,
     "status": "ok",
     "timestamp": 1645093016032,
     "user": {
      "displayName": "Donglai Wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghp_r_BM-hcnzseHQOqKEog51cEpxJX-9EaMyIO=s64",
      "userId": "05000800795689376079"
     },
     "user_tz": 300
    },
    "id": "4ZNB9vWAlZqd",
    "outputId": "20668931-216e-4ec6-849b-408d688a4eb9"
   },
   "outputs": [],
   "source": [
    "# download data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/BlohmLab/MLtutorials/week3/data/marks.txt'\n",
    "data = pd.read_csv(url, header=None)\n",
    "Y = np.array(data.iloc[:,-1]).astype(np.float32).reshape([-1,1])\n",
    "\n",
    "# by default, numpy arrays are float64, but pytorch tensor wants float32\n",
    "X = np.array(data.iloc[:,:-1]).astype(np.float32)\n",
    "# normalize the data for better learning\n",
    "X = (X-X.mean(axis=0))/X.std(axis=0)\n",
    "\n",
    "def data_split(N, ratio=[6,2,2]):\n",
    "  # generate a shuffle array\n",
    "  shuffle_idx = np.arange(N)\n",
    "  np.random.shuffle(shuffle_idx)\n",
    "  # divide into train-val-test by the ratio\n",
    "  data_split = (np.cumsum(ratio)/float(sum(ratio))*N).astype(int)\n",
    "  out_idx = [None] * len(ratio)\n",
    "  out_idx[0] = shuffle_idx[:data_split[0]]\n",
    "  for i in range(1,len(ratio)):\n",
    "    out_idx[i] = shuffle_idx[data_split[i-1] : data_split[i]]\n",
    "  return out_idx  \n",
    "\n",
    "train_idx, val_idx, test_idx = data_split(len(Y))\n",
    "\n",
    "X_train, Y_train = X[train_idx], Y[train_idx]\n",
    "X_val, Y_val = X[val_idx], Y[val_idx]\n",
    "X_test, Y_test = X[test_idx], Y[test_idx]\n",
    "\n",
    "#### TODO: convert variables into pytorch tensors\n",
    "X_train_pt, Y_train_pt = torch.as_tensor(X_train), torch.as_tensor(Y_train)\n",
    "X_val_pt, Y_val_pt = torch.as_tensor(X_val), torch.as_tensor(Y_val)\n",
    "X_test_pt, Y_test_pt = torch.as_tensor(X_test), torch.as_tensor(Y_test)\n",
    "print(X_train_pt.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_logistic_regression(fig, param_W=None, param_b=None, x=X, y=Y, subp=111, title='train'):\n",
    "    # plot original data\n",
    "    X_admitted = x[y==1,:]\n",
    "    X_rejected = x[y==0,:]\n",
    "\n",
    "    ax = fig.add_subplot(subp)\n",
    "    ax.scatter(X_admitted[:,0],X_admitted[:,1])\n",
    "    ax.scatter(X_rejected[:,0],X_rejected[:,1])\n",
    "    ax.set_xlabel('Mark 0')\n",
    "    ax.set_ylabel('Mark 1')\n",
    "    ax.legend(('Accept','Reject'))\n",
    "    \n",
    "    if param_W is not None:\n",
    "        # plot the decision boundary\n",
    "        xx = np.linspace(-2, 2,100)\n",
    "        yy = -param_W[0]/param_W[1]*xx - param_b/param_W[1]\n",
    "        ax.plot(xx,yy,'g-')\n",
    "        plt.title(title)\n",
    "\n",
    "fig = plt.figure()\n",
    "plot_logistic_regression(fig, None, None, X_train, Y_train[:,0], 111, 'train data')\n",
    "plt.show()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tWvTtgKbn6Nx"
   },
   "source": [
    "## (b) Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "izmy6Kr3HWEE"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        # define the layers and parameters\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # this function will be called to process the input data\n",
    "        outputs = F.sigmoid(self.linear(x))\n",
    "        return outputs\n",
    "\n",
    "# create a model (parameters are initialized)\n",
    "# input (size = 2): two exam scores (the bias param will take care of constant term)\n",
    "# ouput (size = 1): accept or not\n",
    "model = LogisticRegression(input_dim = 2, output_dim = 1)\n",
    "\n",
    "# upload the model to GPU\n",
    "# model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z6_pIhHGpaOO"
   },
   "source": [
    "## (c) Optimizer\n",
    "We will use all the data and SGD becomes the same as the gradient descent (GD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M35F6enHq2AY"
   },
   "outputs": [],
   "source": [
    "lr_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ul2Xnrcuwmo5"
   },
   "source": [
    "## (d) Training\n",
    "Well, only 4 important lines!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 275,
     "status": "ok",
     "timestamp": 1645093016473,
     "user": {
      "displayName": "Donglai Wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghp_r_BM-hcnzseHQOqKEog51cEpxJX-9EaMyIO=s64",
      "userId": "05000800795689376079"
     },
     "user_tz": 300
    },
    "id": "XZoO55hiHMrV",
    "outputId": "f2554fed-1a39-4ed1-ebe0-ad8f6c66de22"
   },
   "outputs": [],
   "source": [
    "num_iter = 150\n",
    "# training loop\n",
    "for ii in range(num_iter):\n",
    "    # 1. forward pass\n",
    "    Y_hat = model(X_train_pt)\n",
    "    \n",
    "    # 2. compute loss\n",
    "    loss = F.mse_loss(Y_hat, Y_train_pt)\n",
    "    \n",
    "    # 3. compute gradients\n",
    "    loss.backward()\n",
    "    \n",
    "    # 4. gradient update\n",
    "    optimizer.step()\n",
    "    \n",
    "    # add some printing\n",
    "    if ii % 10 == 0:\n",
    "        print('iteration {}\\tloss {:.5f}'.format(ii, loss))\n",
    "\n",
    "# if the torch tensor has \"require_grad\", need to detach it first\n",
    "ww = model.linear.weight.detach().numpy()[0]\n",
    "bb = model.linear.bias.detach().numpy()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cMpXuc2l0mnn"
   },
   "source": [
    "## (e) Evaluation\n",
    "We will first compute the accuray and plot the predicted decision boundary. Note that the model that fits the training data well, may still have much error on the val and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1645093016474,
     "user": {
      "displayName": "Donglai Wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghp_r_BM-hcnzseHQOqKEog51cEpxJX-9EaMyIO=s64",
      "userId": "05000800795689376079"
     },
     "user_tz": 300
    },
    "id": "F7BKsh860m1a",
    "outputId": "3b01b16f-94b2-4f49-986c-04e8fdbff35e"
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(model, x=X, y=Y):\n",
    "    \"\"\"function that compares predicted y to true y and returns accuracy\"\"\"\n",
    "    y_pred = model(x)>0.5\n",
    "    accuracy = (y_pred == y).sum()/len(y)\n",
    "    return accuracy \n",
    "\n",
    "print('Train acc:', compute_accuracy(model, X_train_pt, Y_train_pt))\n",
    "print('Val acc:', compute_accuracy(model, X_val_pt, Y_test_pt))\n",
    "print('Test acc:', compute_accuracy(model, X_val_pt, Y_test_pt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "executionInfo": {
     "elapsed": 1609,
     "status": "ok",
     "timestamp": 1645093018080,
     "user": {
      "displayName": "Donglai Wei",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghp_r_BM-hcnzseHQOqKEog51cEpxJX-9EaMyIO=s64",
      "userId": "05000800795689376079"
     },
     "user_tz": 300
    },
    "id": "dPLsGQfTwDq-",
    "outputId": "22d3236f-5f20-4c9b-99e3-c4e1e85a623f"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plot_logistic_regression(fig, ww, bb, X_train, Y_train[:,0], 131, 'train')\n",
    "plot_logistic_regression(fig, ww, bb, X_val, Y_val[:,0], 132, 'val')\n",
    "plot_logistic_regression(fig, ww, bb, X_test, Y_test[:,0], 133, 'test')\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lab3_sol.ipynb",
   "provenance": [
    {
     "file_id": "18yIM4-G2U6qPsb-kK5NGko7D3D8fZ8xC",
     "timestamp": 1632715225585
    },
    {
     "file_id": "1IzacTpfzNV-sF4O2NjOXU-GumIOWyqZ-",
     "timestamp": 1615573487743
    },
    {
     "file_id": "1Sw66kxhwaSEVTkM74hvpK2oxZikseOpc",
     "timestamp": 1571367245558
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
