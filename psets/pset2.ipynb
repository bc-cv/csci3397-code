{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QuUAgQFQlsJU"
   },
   "source": [
    "# [CSCI 3397/PSYC 3317] Pset 2: Pathology Image Registration and Segmentation\n",
    "\n",
    "**Posted:** Wednesday, February 23, 2022\n",
    "\n",
    "**Due:** Friday, March 4, 2022\n",
    "\n",
    "__Total Points__: 14 pts\n",
    "\n",
    "__Submission__: please rename the .ipynb file as __\\<your_username\\>_pset2.ipynb__ before you submit it to canvas. Example: weidf_pset2.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GVOsLEGclsJZ"
   },
   "source": [
    "# Welcome to Laboratory of Systems Pharmacology at HMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W0S-Mj2vXTzq"
   },
   "source": [
    "<b>Congratulations</b> for landing a reasearch assistant position at [Prof. Sorger's lab](https://sorger.med.harvard.edu/)!\n",
    "You will be responsible for analyzing immunofluorescence images for pathology. \n",
    "\n",
    "<img height=300 src=\"https://www.cycif.org/assets/img/keenan-2020/cover.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Data loading\n",
    "\n",
    "- Ome.tiff: Latest image format that contains multiple (named as `scenes`) N-dimenstional image volumes. \n",
    "- The data to load are the tiles from mutiple takes of the microscope. It looks similiar to the \"Before Stitching\" visualization  [here](https://mcmicro.org/tutorials/pipeline-visual-guide.html#s=1#w=0#g=0#m=-1#a=-100_-100#v=0.5_0.5_0.5#o=-100_-100_1_1#p=Q) (top-left region, 1 section)\n",
    "- To make your life easier, you will only need to work with the crops from two neighboring tiles prepared for you: `tile0` and `tile1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install aicsimageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aicsimageio.readers.ome_tiff_reader import OmeTiffReader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "im = OmeTiffReader('../labs/lab3/exemplar-001-cycle-01.ome.tiff')\n",
    "\n",
    "num_scenes = len(im.scenes)\n",
    "num_disp_col = 2\n",
    "num_disp_row = (num_scenes + num_disp_col - 1) // num_disp_col\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "for scene_id in range(num_scenes):    \n",
    "    im.set_scene(scene_id)\n",
    "    tile = im.get_image_data()\n",
    "    plt.subplot(num_disp_row, num_disp_col, scene_id+1)\n",
    "    plt.imshow(tile[0,0,0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from T_util import * \n",
    "# import handy functions in T_util\n",
    "\n",
    "im.set_scene(0)\n",
    "tile = imAdjust(im.get_image_data())\n",
    "tile0 = tile[0,0,0,:256,-256:]\n",
    "im.set_scene(1)\n",
    "tile = imAdjust(im.get_image_data())\n",
    "tile1 = tile[0,0,0,:256,:256]\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plotImgPair(tile0, tile1, title=['tile0', 'tile1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "weMMc2WZlsJc"
   },
   "source": [
    "# 1. (9 pts) Image Stitching [[link]](https://en.wikipedia.org/wiki/Image_stitching)\n",
    "\n",
    "<b>Prof. Sorger: Please stitch these two tiles into one image. </b>\n",
    "\n",
    "TODO: \n",
    "- (a) [1 pt] Create and visualize the no-stitch solution. Directly concatenate these two tiles side-by-side (left-right).\n",
    "- (b) [2 pts] Crop out the roughly aligned regions from both tiles (keep all rows, only select the columns): `tile0_crop, tile1_crop`. Use the RGB visualization for these two images. (AKA. transform the stitching problem into the alignment problem)\n",
    "- (c) [3 pts] Use the 3-step pipeline approach to find the affine transformation between the two cropped tiles (`tile0_crop, tile1_crop`). \n",
    "- (d) [1 pt] Use RGB visualization to check the alignment result between (`tile0_crop, tile1_crop`).\n",
    "- (e) [2 pts] Stitch and visualize the two tiles (`tile0, tile1`) into one image based on the estimated affine transformation. \n",
    "\n",
    "Hints: \n",
    "- Lec. 5 (image registration), lab3b\n",
    "- (a) Notice that the right part of `tile0` matches to the left part of `tile1`.\n",
    "- (b) Use all columns. Sth. like `image[:, col_start:col_end]`\n",
    "- (c) For feature computation, use [SIFT](https://docs.opencv.org/4.x/da/df5/tutorial_py_sift_intro.html) (`cv2.xfeatures2d.SIFT_create()`) instead of [ORB](https://docs.opencv.org/3.4/d1/d89/tutorial_py_orb.html). Otherwise, it's hard to find good matches.\n",
    "- (e) You can (1) create a big image filled with 0 (similar to (a)), (2) warp `tile1` with the affine transformation and assign it to the corresponding location (remember the starting column index that you cropped), (3) assign `tile0` to the big image, overwriting warped `tile1` values for the overlapping region. (There are fancy method to blend the overlapping region if you are interested to read about [(link)](http://graphics.cs.cmu.edu/courses/15-463/2010_spring/Lectures/blending.pdf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a)\n",
    "### Your code starts here\n",
    "\n",
    "### Your code ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (b)\n",
    "### Your code starts here\n",
    "\n",
    "### Your code ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (c)\n",
    "### Your code starts here\n",
    "\n",
    "### Your code ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (d)\n",
    "### Your code starts here\n",
    "\n",
    "### Your code ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (e)\n",
    "### Your code starts here\n",
    "\n",
    "### Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. (5 pts) Image Segmentation\n",
    "\n",
    "<b>Prof. Sorger: Good job! Please segment the stitched image into cells. </b>\n",
    "\n",
    "TODO: \n",
    "- (a) [4 pts] Apply the watershed segmentation for the cells.\n",
    "- (b) [1 pt] Save the result into a csv file `cell_stats.csv` with header: {\"cell id\", \"area\"}\n",
    "\n",
    "Hints: \n",
    "- Lec. 6-7 (instance segmentation), lab4b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bPWkPZ-3lsJ3"
   },
   "outputs": [],
   "source": [
    "### Your code starts here\n",
    "\n",
    "### Your code ends here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "lab1.ipynb",
   "provenance": [
    {
     "file_id": "1_d49_U8Zrz_Ac-QWgXFBzr4CJ4S8fKe1",
     "timestamp": 1614174979410
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
